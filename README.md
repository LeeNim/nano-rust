# ðŸ§  NANO-RUST-AI

**TinyML Framework for Embedded Devices â€” Rust `no_std` Core + Python Bindings**

Train in PyTorch â†’ Quantize (i8) â†’ Run on MCU (ESP32, STM32, Cortex-M)

---

## âœ¨ Features

- **ðŸ”’ No Heap**: Pure `no_std` â€” zero `malloc`, zero dynamic allocation
- **âš¡ Int8 Quantization**: All compute in i8/i32 for 4Ã— memory savings over f32
- **ðŸ§Š Hybrid Memory**: Frozen weights in Flash (0 bytes RAM), trainable head in RAM
- **ðŸŽ¯ Scale-Aware Requantization**: TFLite-style `(acc Ã— M) >> shift` for accurate i8 output
- **ðŸ Python Bindings**: PyO3 wrapper for seamless PyTorch â†’ NANO-RUST pipeline
- **ðŸ“¦ Arena Allocator**: User provides `&mut [u8]` buffer â€” library self-manages within it

---

## ðŸ“‹ Quick Start

### 1. Prerequisites

| Tool | Version |
|------|---------|
| Rust | 1.70+ (`rustup install stable`) |
| Python | 3.9+ |
| maturin | `pip install maturin` |

### 2. Create Virtual Environment

```bash
# Create and activate venv
python -m venv .venv

# Windows
.venv\Scripts\activate

# Linux/Mac
source .venv/bin/activate

# Install dependencies
pip install maturin numpy torch torchvision jupyter ipykernel
```

### 3. Build & Install the Library

```bash
# IMPORTANT: Set CARGO_TARGET_DIR outside OneDrive to avoid file locking
# Windows PowerShell:
$env:CARGO_TARGET_DIR = "$env:USERPROFILE\.nanorust_target"

# Build and install into the active venv
maturin develop --release
```

### 4. Register Jupyter Kernel (for notebooks)

```bash
python -m ipykernel install --user --name nanorust --display-name "NanoRust (venv)"
```

Then select the **"NanoRust (venv)"** kernel in Jupyter when running notebooks.

---

## ðŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Python (PyTorch + nano_rust_utils)  â”‚  â† Train & Quantize
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  PyO3 Binding (nano_rust_py)         â”‚  â† Bridge
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Rust Core (nano-rust-core)          â”‚  â† Inference Engine
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ math.rsâ”‚ â”‚layers/ â”‚ â”‚arena.rs â”‚  â”‚
â”‚  â”‚ matmul â”‚ â”‚dense   â”‚ â”‚bump ptr â”‚  â”‚
â”‚  â”‚ conv2d â”‚ â”‚conv    â”‚ â”‚ckpt/rst â”‚  â”‚
â”‚  â”‚ relu   â”‚ â”‚pool    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”‚sigmoid â”‚ â”‚flatten â”‚              â”‚
â”‚  â”‚ tanh   â”‚ â”‚activateâ”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Memory Layout on MCU

```
FLASH (4MB)                    RAM (320KB)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Frozen Backbone     â”‚        â”‚ Arena Buffer      â”‚
â”‚ - Conv2D weights    â”‚        â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ - Dense weights     â”‚        â”‚ â”‚ Intermediate â”‚  â”‚
â”‚ - Bias arrays       â”‚        â”‚ â”‚ activations  â”‚  â”‚
â”‚ (read-only, static) â”‚        â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚                     â”‚        â”‚ â”‚ Trainable    â”‚  â”‚
â”‚                     â”‚        â”‚ â”‚ Head weights â”‚  â”‚
â”‚                     â”‚        â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ Python API Reference

### `nano_rust_py.PySequentialModel`

```python
model = nano_rust_py.PySequentialModel(
    input_shape=[C, H, W],    # or [N] for 1D
    arena_size=32768           # bytes for scratch memory
)
```

### Layer Methods

| Method | Description |
|--------|-------------|
| `add_dense(weights, bias)` | Dense layer (i8 weights/bias as lists) |
| `add_dense_with_requant(weights, bias, M, shift)` | Dense with calibrated requant |
| `add_conv2d(kernel, bias, in_ch, out_ch, kh, kw, stride, padding)` | Conv2D layer |
| `add_conv2d_with_requant(kernel, bias, in_ch, out_ch, kh, kw, stride, padding, M, shift)` | Conv2D with calibrated requant |
| `add_trainable_dense(in_features, out_features)` | Trainable Dense (RAM weights) |
| `add_relu()` | ReLU activation |
| `add_sigmoid()` | Sigmoid (fixed scale, for general use) |
| `add_sigmoid_scaled(scale_mult, scale_shift)` | Sigmoid with scale-aware LUT |
| `add_tanh()` | Tanh (fixed scale, for general use) |
| `add_tanh_scaled(scale_mult, scale_shift)` | Tanh with scale-aware LUT |
| `add_softmax()` | Softmax (pseudo-probabilities) |
| `add_flatten()` | Flatten 3Dâ†’1D |
| `add_max_pool2d(kernel, stride, padding)` | MaxPool2D |

### Inference

```python
output = model.forward(input_i8_list)  # Returns list of i8 values
```

### Python Utilities (`scripts/nano_rust_utils.py`)

```python
from nano_rust_utils import quantize_to_i8, quantize_weights, calibrate_model

# Quantize input
q_input, input_scale = quantize_to_i8(float_array)

# Quantize model weights
q_weights = quantize_weights(pytorch_model)

# Calibrate requantization parameters
requant = calibrate_model(model, input_tensor, q_weights, input_scale)
# Returns dict: layer_name â†’ (M, shift, bias_corrected) for parametric layers
#                             ('sigmoid', mult, shift) for Sigmoid
#                             ('tanh', mult, shift) for Tanh
```

---

## ðŸ““ Notebooks

### Validation Notebooks (`notebooks/`)

Quick-run notebooks using `_setup.py` for auto-build:

| # | File | Description |
|---|------|-------------|
| 01 | `01_pipeline_validation.ipynb` | Convâ†’ReLUâ†’Flattenâ†’Dense end-to-end |
| 02 | `02_mlp_classification.ipynb` | MLP (Denseâ†’ReLUâ†’Dense) |
| 03 | `03_deep_cnn.ipynb` | Deep CNN with MaxPool |
| 04 | `04_activation_functions.ipynb` | ReLU vs Sigmoid vs Tanh comparison |
| 05 | `05_transfer_learning.ipynb` | Frozen backbone + trainable head |

### Real-World Test Scripts (`notebooks-for-test/`)

GPU-accelerated training â†’ i8 quantization â†’ NANO-RUST verification:

| # | File | Task | Accuracy |
|---|------|------|----------|
| 06 | `run_06_mnist.py` | MNIST digit classification (CNN) | ~97% |
| 07 | `run_07_fashion.py` | Fashion item classification (CNN) | ~87% |
| 08 | `run_08_sensor.py` | Industrial sensor fusion (MLP) | ~98% |
| 09 | `run_09_keyword_spotting.py` | Voice keyword spotting (MFCC+MLP) | ~79% |
| 10 | `run_10_text_classifier.py` | Text classification (BoW+MLP) | 100% |

Run all tests:
```bash
python notebooks-for-test/run_06_mnist.py
# ... etc
```

---

## ðŸš€ ESP32 Deployment Guide

### Step 1: Train & Export in Python

```python
import torch.nn as nn
from nano_rust_utils import quantize_weights, calibrate_model, export_to_rust

# 1. Train your PyTorch model
model = nn.Sequential(
    nn.Linear(416, 128), nn.ReLU(),
    nn.Linear(128, 64), nn.ReLU(),
    nn.Linear(64, 10),
)
# ... train on GPU ...

# 2. Quantize & calibrate
q_weights = quantize_weights(model)
requant = calibrate_model(model, sample_input, q_weights, input_scale)

# 3. Export to Rust source code
rust_code = export_to_rust(model, "keyword_model", input_shape=[416])
with open("model.rs", "w") as f:
    f.write(rust_code)
```

### Step 2: Use in ESP32 Rust Firmware

```rust
#![no_std]
use nano_rust_core::{Arena, model::SequentialModel};

// Generated model from export_to_rust()
include!("model.rs");

#[entry]
fn main() -> ! {
    // Arena in RAM â€” size from model.estimate_arena_size()
    let mut arena_buf = [0u8; 16384];

    loop {
        // Get sensor/audio data â†’ quantize to i8
        let input: [i8; 416] = read_mfcc_features();

        // Run inference (< 1ms on ESP32 @ 240MHz)
        let mut arena = Arena::new(&mut arena_buf);
        let model = build_keyword_model();  // From generated code
        let (output, _) = model.forward(&input, &[416], &mut arena).unwrap();

        let predicted_class = output.iter()
            .enumerate()
            .max_by_key(|(_, v)| **v)
            .map(|(i, _)| i)
            .unwrap();
    }
}
```

### Memory Budget (ESP32)

| Component | Flash | RAM |
|-----------|-------|-----|
| Frozen weights | 60KB | 0B |
| Arena buffer | 0B | 16KB |
| Code + stack | ~20KB | ~4KB |
| **Total** | **~80KB** | **~20KB** |
| **Available** | **4MB** | **520KB** |

---

## ðŸ”§ Rust Core API (`nano-rust-core`)

### Layers

```rust
use nano_rust_core::layers::*;

// Frozen (Flash) â€” 0 bytes RAM for weights
let dense = FrozenDense::new_with_requant(weights, bias, in_f, out_f, M, shift)?;
let conv = FrozenConv2D::new_with_requant(kernel, bias, in_ch, out_ch, kh, kw, s, p, M, shift)?;

// Trainable (RAM) â€” weights allocated in Arena
let head = TrainableDense::new(in_features, out_features);

// Activations
let _ = ReLULayer;
let _ = ScaledSigmoidLayer { scale_mult: 42, scale_shift: 8 };
let _ = ScaledTanhLayer { scale_mult: 84, scale_shift: 8 };
let _ = SoftmaxLayer;

// Structural
let _ = FlattenLayer;
let _ = MaxPool2DLayer::new(2, 2, 0)?;
```

### Arena Allocator

```rust
use nano_rust_core::Arena;

let mut buf = [0u8; 32768];
let mut arena = Arena::new(&mut buf);

// Checkpoint/restore for scratch memory reuse
let cp = arena.checkpoint();
let scratch = arena.alloc_i8_slice(1024)?;
arena.restore(cp);  // reclaim scratch memory
```

### Sequential Model

```rust
use nano_rust_core::model::SequentialModel;

let mut model = SequentialModel::new();
model.add(Box::new(dense));
model.add(Box::new(ReLULayer));
let (output, shape) = model.forward(input, &input_shape, &mut arena)?;
```

---

## ðŸ“Š Accuracy Targets

| Model Type | Expected Max Diff (vs PyTorch) |
|------------|-------------------------------|
| Dense + ReLU | â‰¤ 3 |
| Conv + ReLU + Dense | â‰¤ 5 |
| Deep CNN + Pool | â‰¤ 10 |
| Sigmoid/Tanh (scaled) | â‰¤ 20 |

---

## ðŸ—‚ï¸ Project Structure

```
nano-rust/
â”œâ”€â”€ core/                    # Rust no_std core library
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ lib.rs           # Crate root
â”‚       â”œâ”€â”€ arena.rs         # Bump pointer allocator
â”‚       â”œâ”€â”€ math.rs          # Matmul, conv2d, activations
â”‚       â”œâ”€â”€ error.rs         # Error types
â”‚       â”œâ”€â”€ model.rs         # SequentialModel
â”‚       â””â”€â”€ layers/
â”‚           â”œâ”€â”€ mod.rs       # Layer trait + Shape
â”‚           â”œâ”€â”€ dense.rs     # FrozenDense + TrainableDense
â”‚           â”œâ”€â”€ conv.rs      # FrozenConv2D
â”‚           â”œâ”€â”€ activations.rs  # ReLU, Sigmoid, Tanh, Softmax
â”‚           â”œâ”€â”€ flatten.rs   # Flatten layer
â”‚           â””â”€â”€ pooling.rs   # MaxPool2D
â”œâ”€â”€ py_binding/              # PyO3 Python bindings
â”‚   â””â”€â”€ src/lib.rs
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ nano_rust_utils.py   # Quantization + calibration utilities
â”‚   â””â”€â”€ export.py            # CLI weight exporter
â”œâ”€â”€ notebooks/               # Quick validation notebooks (01-05)
â”œâ”€â”€ notebooks-for-test/      # Real-world test scripts (06-10)
â”œâ”€â”€ pyproject.toml           # pip install configuration
â”œâ”€â”€ Cargo.toml               # Workspace config
â”œâ”€â”€ LICENSE                  # MIT License
â””â”€â”€ README.md
```

---

## ðŸ“œ License

[MIT](LICENSE)

---

## ðŸ”® Roadmap

- [x] v0.1.0: Core inference engine with scale-aware requantization
- [ ] v0.2.0: Const Generics refactor for compile-time optimization
- [ ] v0.3.0: On-device training (backprop for trainable head)
- [ ] v0.4.0: ARM SIMD intrinsics (SMLAD) for Cortex-M
