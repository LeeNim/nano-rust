{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 05 — Transfer Learning: Frozen Backbone + Trainable Head\n",
                "\n",
                "- **Frozen backbone** (Flash): `Conv2D(1→4) → ReLU`\n",
                "- **Trainable head** (RAM): `Flatten → Dense(400→10)`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from _setup import setup_all, PROJECT_ROOT\n",
                "setup_all()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "from nano_rust_utils import quantize_to_i8, quantize_weights, calibrate_model\n",
                "import nano_rust_py\n",
                "\n",
                "torch.manual_seed(42)\n",
                "full_model = nn.Sequential(\n",
                "    nn.Conv2d(1, 4, kernel_size=3, stride=1, padding=0),  # [1,12,12]→[4,10,10]\n",
                "    nn.ReLU(),\n",
                "    nn.Flatten(),\n",
                "    nn.Linear(400, 10),\n",
                ")\n",
                "full_model.eval()\n",
                "\n",
                "q_weights = quantize_weights(full_model)\n",
                "\n",
                "torch.manual_seed(123)\n",
                "input_tensor = torch.randn(1, 1, 12, 12)\n",
                "q_input, input_scale = quantize_to_i8(input_tensor.numpy().flatten())\n",
                "\n",
                "requant = calibrate_model(full_model, input_tensor, q_weights, input_scale)\n",
                "print('Requant:', {k: (m, s) for k, (m, s, _) in requant.items()})"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "with torch.no_grad():\n",
                "    pytorch_out = full_model(input_tensor).numpy().flatten()\n",
                "\n",
                "nano = nano_rust_py.PySequentialModel(input_shape=[1, 12, 12], arena_size=65536)\n",
                "\n",
                "m0, s0, b0 = requant['0']\n",
                "nano.add_conv2d_with_requant(\n",
                "    q_weights['0']['weights'].flatten().tolist(), b0,\n",
                "    1, 4, 3, 3, 1, 0, m0, s0)\n",
                "nano.add_relu()\n",
                "nano.add_flatten()\n",
                "\n",
                "m3, s3, b3 = requant['3']\n",
                "nano.add_dense_with_requant(\n",
                "    q_weights['3']['weights'].flatten().tolist(), b3, m3, s3)\n",
                "\n",
                "nano_out = nano.forward(q_input.tolist())\n",
                "\n",
                "q_pytorch, _ = quantize_to_i8(pytorch_out)\n",
                "nano_arr = np.array(nano_out, dtype=np.int8)\n",
                "diff = np.abs(q_pytorch.astype(np.int32) - nano_arr.astype(np.int32))\n",
                "\n",
                "print(f'PyTorch (i8):  {q_pytorch.tolist()}')\n",
                "print(f'NANO-RUST:     {nano_arr.tolist()}')\n",
                "print(f'Max diff: {np.max(diff)}, Mean diff: {np.mean(diff):.2f}')\n",
                "print(f'Class: PyTorch={np.argmax(q_pytorch)}, NANO-RUST={np.argmax(nano_arr)}')\n",
                "print(f'\\n{\"✅ PASS\" if np.max(diff) <= 20 else \"❌ FAIL\"} (tolerance=20)')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Memory budget\n",
                "conv_bytes = q_weights['0']['weights'].nbytes + len(requant['0'][2])\n",
                "dense_bytes = q_weights['3']['weights'].nbytes + len(requant['3'][2])\n",
                "print(f'\\nBackbone (Flash): {conv_bytes:>6} bytes ({conv_bytes/1024:.1f} KB)')\n",
                "print(f'Head (RAM):       {dense_bytes:>6} bytes ({dense_bytes/1024:.1f} KB)')\n",
                "print(f'Total:            {conv_bytes+dense_bytes:>6} bytes ({(conv_bytes+dense_bytes)/1024:.1f} KB)')\n",
                "print(f'\\nFits in ESP32 (520KB RAM)? {\"✅ Yes\" if dense_bytes < 520*1024 else \"❌ No\"}')\n",
                "print(f'Fits in STM32F4 (192KB RAM)? {\"✅ Yes\" if dense_bytes < 192*1024 else \"❌ No\"}')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.13.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
