{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 01 â€” Full Pipeline Validation\n",
                "\n",
                "**Goal**: Verify the complete `PyTorch â†’ Quantize â†’ NANO-RUST` pipeline.\n",
                "\n",
                "**Model**: `Conv2D(1â†’4, 3Ã—3) â†’ ReLU â†’ Flatten â†’ Dense(144â†’10)`\n",
                "\n",
                "**What this notebook demonstrates**:\n",
                "1. Define a CNN model in PyTorch\n",
                "2. Quantize weights to i8 using `quantize_weights()`\n",
                "3. Calibrate requantization using `calibrate_model()`\n",
                "4. Build the same model in NANO-RUST with i8 weights\n",
                "5. Compare outputs bit-by-bit\n",
                "\n",
                "**Prerequisites**: `pip install nano-rust-py numpy torch`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "\n",
                "import numpy as np\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "\n",
                "from nano_rust_py.utils import quantize_to_i8, quantize_weights, calibrate_model\n",
                "import nano_rust_py\n",
                "\n",
                "print('âœ… All imports OK')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Define PyTorch Model\n",
                "\n",
                "A simple CNN for 8Ã—8 single-channel images (like a tiny grayscale sensor grid).\n",
                "\n",
                "| Layer | Input | Output | Params |\n",
                "|-------|-------|--------|--------|\n",
                "| Conv2d(1â†’4, 3Ã—3) | [1, 8, 8] | [4, 6, 6] | 36 + 4 = 40 |\n",
                "| ReLU | [4, 6, 6] | [4, 6, 6] | 0 |\n",
                "| Flatten | [4, 6, 6] | [144] | 0 |\n",
                "| Linear(144â†’10) | [144] | [10] | 1440 + 10 = 1450 |\n",
                "| **Total** | | | **1,490** |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "torch.manual_seed(42)\n",
                "model = nn.Sequential(\n",
                "    nn.Conv2d(1, 4, kernel_size=3, stride=1, padding=0, bias=True),\n",
                "    nn.ReLU(),\n",
                "    nn.Flatten(),\n",
                "    nn.Linear(4 * 6 * 6, 10, bias=True),\n",
                ")\n",
                "model.eval()\n",
                "\n",
                "print(model)\n",
                "print(f'Total parameters: {sum(p.numel() for p in model.parameters()):,}')\n",
                "print(f'Float32 size: {sum(p.numel() for p in model.parameters()) * 4:,} bytes')\n",
                "print(f'Int8 size:    {sum(p.numel() for p in model.parameters()):,} bytes (4Ã— smaller)')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Quantize Weights & Calibrate\n",
                "\n",
                "**Quantization**: Convert float32 weights to i8 using symmetric linear scaling.\n",
                "- Each layer's max absolute weight maps to Â±127\n",
                "- Scale factor = max_abs / 127\n",
                "\n",
                "**Calibration**: Run a sample input through the float model to compute:\n",
                "- `requant_m`: Fixed-point multiplier for `(acc Ã— M) >> shift`\n",
                "- `requant_shift`: Bit-shift for the above formula\n",
                "- `bias_corrected`: Bias pre-scaled to match output quantization scale"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Quantize all model weights to i8\n",
                "q_weights = quantize_weights(model)\n",
                "for name, info in q_weights.items():\n",
                "    print(f'Layer {name} ({info[\"type\"]}): '\n",
                "          f'{info[\"weights\"].shape} â†’ {info[\"weights\"].size} bytes, '\n",
                "          f'scale={info[\"weight_scale\"]:.6f}')\n",
                "\n",
                "# Create a random test input\n",
                "torch.manual_seed(42)\n",
                "input_tensor = torch.randn(1, 1, 8, 8)  # batch=1, channels=1, 8Ã—8\n",
                "q_input, input_scale = quantize_to_i8(input_tensor.numpy().flatten())\n",
                "print(f'\\nInput scale: {input_scale:.6f}')\n",
                "print(f'Input range: [{q_input.min()}, {q_input.max()}]')\n",
                "\n",
                "# Calibrate requantization parameters\n",
                "requant = calibrate_model(model, input_tensor, q_weights, input_scale)\n",
                "print('\\n=== Calibrated Requant Params ===')\n",
                "for name, (m, s, bc) in requant.items():\n",
                "    print(f'  Layer {name}: M={m}, shift={s}, bias_corrected={bc}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Build NANO-RUST Model & Compare\n",
                "\n",
                "Now we build the exact same model architecture using `nano_rust_py`:\n",
                "- Use i8 weights from `quantize_weights()`\n",
                "- Use calibrated `requant_m` and `requant_shift` from `calibrate_model()`\n",
                "- Use corrected bias (already in output scale)\n",
                "\n",
                "Then run the same input through both and compare the output."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- PyTorch reference output ---\n",
                "with torch.no_grad():\n",
                "    pytorch_float_output = model(input_tensor).numpy().flatten()\n",
                "q_pytorch, _ = quantize_to_i8(pytorch_float_output)\n",
                "\n",
                "# --- NANO-RUST model ---\n",
                "nano = nano_rust_py.PySequentialModel(input_shape=[1, 8, 8], arena_size=32768)\n",
                "\n",
                "# Add Conv2D with calibrated requant\n",
                "conv_m, conv_s, conv_bias = requant['0']\n",
                "nano.add_conv2d_with_requant(\n",
                "    q_weights['0']['weights'].flatten().tolist(),\n",
                "    conv_bias,\n",
                "    1, 4, 3, 3, 1, 0,  # in_ch, out_ch, kh, kw, stride, padding\n",
                "    conv_m, conv_s\n",
                ")\n",
                "nano.add_relu()\n",
                "nano.add_flatten()\n",
                "\n",
                "# Add Dense with calibrated requant\n",
                "dense_m, dense_s, dense_bias = requant['3']\n",
                "nano.add_dense_with_requant(\n",
                "    q_weights['3']['weights'].flatten().tolist(),\n",
                "    dense_bias,\n",
                "    dense_m, dense_s\n",
                ")\n",
                "\n",
                "# Run inference\n",
                "nano_output = nano.forward(q_input.tolist())\n",
                "nano_arr = np.array(nano_output, dtype=np.int8)\n",
                "\n",
                "# --- Compare ---\n",
                "diff = np.abs(q_pytorch.astype(np.int32) - nano_arr.astype(np.int32))\n",
                "TOLERANCE = 20\n",
                "\n",
                "print('=' * 50)\n",
                "print('       PIPELINE VALIDATION RESULTS')\n",
                "print('=' * 50)\n",
                "print(f'PyTorch (i8): {q_pytorch.tolist()}')\n",
                "print(f'NANO-RUST:    {nano_arr.tolist()}')\n",
                "print(f'Max diff:     {int(np.max(diff))}')\n",
                "print(f'Mean diff:    {float(np.mean(diff)):.2f}')\n",
                "print(f'PyTorch class:  {int(np.argmax(q_pytorch))}')\n",
                "print(f'NANO-RUST class:{int(np.argmax(nano_arr))}')\n",
                "print('-' * 50)\n",
                "ok = int(np.max(diff)) <= TOLERANCE\n",
                "print(f'{\"âœ… Numerical: PASS\" if ok else \"âŒ Numerical: FAIL\"} (tolerance={TOLERANCE})')\n",
                "match = int(np.argmax(q_pytorch)) == int(np.argmax(nano_arr))\n",
                "print(f'{\"âœ… Classification: AGREE\" if match else \"âš ï¸ Classification: DISAGREE\"}')\n",
                "print('=' * 50)\n",
                "print('ðŸŽ‰ PASSED!' if ok and match else 'âš ï¸ Check results above')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
