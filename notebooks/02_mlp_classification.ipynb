{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 02 — MLP Classification\n",
                "\n",
                "**Goal**: Build a multi-layer perceptron (Dense→ReLU→Dense) and verify quantization.\n",
                "\n",
                "**Model**: `Linear(784→128) → ReLU → Linear(128→10)`\n",
                "\n",
                "This is the simplest real-world architecture: a 2-layer MLP for classifying\n",
                "784-dimensional inputs (like MNIST flattened) into 10 classes.\n",
                "\n",
                "**What you'll learn**:\n",
                "- How weight quantization works (float32 → i8)\n",
                "- How calibrated vs uncalibrated requantization affects accuracy\n",
                "- RAM budget: these weights would use only 100KB Flash on an MCU\n",
                "\n",
                "**Prerequisites**: `pip install nano-rust-py numpy torch`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "\n",
                "import numpy as np\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "\n",
                "from nano_rust_py.utils import quantize_to_i8, quantize_weights, calibrate_model\n",
                "import nano_rust_py\n",
                "\n",
                "print('✅ All imports OK')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Define MLP Model\n",
                "\n",
                "| Layer | Shape | Params | Flash (i8) | RAM |\n",
                "|-------|-------|--------|------------|-----|\n",
                "| Linear(784→128) | [784] → [128] | 100,480 | 100KB | 0 |\n",
                "| ReLU | [128] → [128] | 0 | 0 | 0 |\n",
                "| Linear(128→10) | [128] → [10] | 1,290 | 1.3KB | 0 |\n",
                "| **Total** | | **101,770** | **~100KB** | **0** |\n",
                "\n",
                "Arena buffer needed: `2 × max(128, 10) × 1 = 256 bytes`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "torch.manual_seed(42)\n",
                "model = nn.Sequential(\n",
                "    nn.Linear(784, 128),\n",
                "    nn.ReLU(),\n",
                "    nn.Linear(128, 10),\n",
                ")\n",
                "model.eval()\n",
                "\n",
                "total = sum(p.numel() for p in model.parameters())\n",
                "print(model)\n",
                "print(f'\\nParameters: {total:,}')\n",
                "print(f'Float32: {total * 4 / 1024:.1f} KB')\n",
                "print(f'Int8:    {total / 1024:.1f} KB (4× compression)')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Quantize & Calibrate\n",
                "\n",
                "The quantization pipeline:\n",
                "1. `quantize_weights(model)` → extracts all weight matrices, scales each to i8\n",
                "2. `quantize_to_i8(input)` → scales the input tensor to i8\n",
                "3. `calibrate_model()` → computes exact requantization params by running the float model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "q_weights = quantize_weights(model)\n",
                "\n",
                "# Random test input (784 features, like a flattened 28×28 MNIST image)\n",
                "torch.manual_seed(42)\n",
                "input_tensor = torch.randn(1, 784)\n",
                "q_input, input_scale = quantize_to_i8(input_tensor.numpy().flatten())\n",
                "print(f'Input quantized: {q_input.shape}, scale={input_scale:.6f}')\n",
                "\n",
                "requant = calibrate_model(model, input_tensor, q_weights, input_scale)\n",
                "for name, (m, s, bc) in requant.items():\n",
                "    print(f'Layer {name}: requant_m={m}, shift={s}, corrected_bias_len={len(bc)}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Build NANO-RUST Model & Compare"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# PyTorch reference\n",
                "with torch.no_grad():\n",
                "    pytorch_out = model(input_tensor).numpy().flatten()\n",
                "q_pytorch, _ = quantize_to_i8(pytorch_out)\n",
                "\n",
                "# NANO-RUST model\n",
                "nano = nano_rust_py.PySequentialModel(input_shape=[784], arena_size=4096)\n",
                "\n",
                "m0, s0, b0 = requant['0']\n",
                "nano.add_dense_with_requant(\n",
                "    q_weights['0']['weights'].flatten().tolist(), b0, m0, s0\n",
                ")\n",
                "nano.add_relu()\n",
                "\n",
                "m2, s2, b2 = requant['2']\n",
                "nano.add_dense_with_requant(\n",
                "    q_weights['2']['weights'].flatten().tolist(), b2, m2, s2\n",
                ")\n",
                "\n",
                "nano_output = nano.forward(q_input.tolist())\n",
                "nano_arr = np.array(nano_output, dtype=np.int8)\n",
                "\n",
                "# Compare\n",
                "diff = np.abs(q_pytorch.astype(np.int32) - nano_arr.astype(np.int32))\n",
                "print(f'PyTorch (i8): {q_pytorch.tolist()}')\n",
                "print(f'NANO-RUST:    {nano_arr.tolist()}')\n",
                "print(f'Max diff: {int(np.max(diff))}, Mean diff: {float(np.mean(diff)):.2f}')\n",
                "print(f'Classes match: {np.argmax(q_pytorch) == np.argmax(nano_arr)}')\n",
                "print('\\n✅ PASSED!' if np.max(diff) <= 10 else '\\n⚠️ Large diff, check calibration')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
