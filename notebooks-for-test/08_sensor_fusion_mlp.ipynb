{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08 \u2014 Sensor Fusion MLP (Multi-Sensor \u2192 Classification)\n",
    "\n",
    "**Scenario**: Industrial vibration monitoring \u2014 classify machine state from IMU sensor data.\n",
    "\n",
    "Architecture: `Dense(6\u219232) \u2192 ReLU \u2192 Dense(32\u219216) \u2192 ReLU \u2192 Dense(16\u21924)`\n",
    "\n",
    "Input: 6 features (accel_x, accel_y, accel_z, gyro_x, gyro_y, gyro_z)\n",
    "Output: 4 classes (normal, bearing_fault, misalignment, imbalance)\n",
    "\n",
    "### Setup\n",
    "Ensure **NanoRust (venv)** kernel is selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run _setup.py\n",
    "setup_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from nano_rust_utils import quantize_to_i8, quantize_weights, calibrate_model\n",
    "import nano_rust_py\n",
    "\n",
    "CLASSES = ['Normal', 'Bearing Fault', 'Misalignment', 'Imbalance']\n",
    "print('\u2705 Modules loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic IMU sensor data\n",
    "np.random.seed(42)\n",
    "N_PER_CLASS = 500\n",
    "N_FEATURES = 6  # accel_xyz + gyro_xyz\n",
    "\n",
    "def generate_sensor_data(n, class_id):\n",
    "    \"\"\"Generate synthetic vibration data with class-specific patterns.\"\"\"\n",
    "    base = np.random.randn(n, N_FEATURES) * 0.3\n",
    "    if class_id == 0:  # Normal: low amplitude, balanced\n",
    "        base *= 0.5\n",
    "    elif class_id == 1:  # Bearing fault: high-freq spikes in accel\n",
    "        base[:, :3] += np.random.choice([-1, 1], (n, 3)) * np.random.exponential(0.8, (n, 3))\n",
    "    elif class_id == 2:  # Misalignment: correlated accel/gyro\n",
    "        base[:, 3:] = base[:, :3] * 0.7 + np.random.randn(n, 3) * 0.2\n",
    "    elif class_id == 3:  # Imbalance: periodic in one axis\n",
    "        base[:, 0] += np.sin(np.linspace(0, 4*np.pi, n)) * 1.2\n",
    "        base[:, 3] += np.cos(np.linspace(0, 4*np.pi, n)) * 0.8\n",
    "    return base\n",
    "\n",
    "X_all, y_all = [], []\n",
    "for c in range(4):\n",
    "    X_all.append(generate_sensor_data(N_PER_CLASS, c))\n",
    "    y_all.extend([c] * N_PER_CLASS)\n",
    "\n",
    "X = np.vstack(X_all).astype(np.float32)\n",
    "y = np.array(y_all, dtype=np.int64)\n",
    "\n",
    "# Shuffle and split\n",
    "idx = np.random.permutation(len(X))\n",
    "X, y = X[idx], y[idx]\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "train_ds = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "test_ds = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "\n",
    "print(f'Train: {len(train_ds)}, Test: {len(test_ds)}')\n",
    "print(f'Features: {N_FEATURES}, Classes: {len(CLASSES)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Model\n",
    "\n",
    "# GPU Setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "if device.type == 'cuda':\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(6, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 4),\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    correct, total = 0, 0\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = criterion(out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        correct += out.argmax(1).eq(target).sum().item()\n",
    "        total += target.size(0)\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f'Epoch {epoch+1}/20 \u2014 Acc: {100.*correct/total:.1f}%')\n",
    "\n",
    "model.eval()\n",
    "print('\u2705 Training complete')\n",
    "\n",
    "model = model.to(device)\n",
    "print(\"Model moved to device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantize & calibrate\n",
    "q_weights = quantize_weights(model)\n",
    "cal_input = torch.from_numpy(X_test[:1])\n",
    "q_cal, cal_scale = quantize_to_i8(cal_input.numpy().flatten())\n",
    "requant = calibrate_model(model, cal_input, q_weights, cal_scale)\n",
    "\n",
    "def build_nano():\n",
    "    nano = nano_rust_py.PySequentialModel(input_shape=[6], arena_size=4096)\n",
    "    m, s, bc = requant['0']\n",
    "    nano.add_dense_with_requant(q_weights['0']['weights'].flatten().tolist(), bc, m, s)\n",
    "    nano.add_relu()\n",
    "    m, s, bc = requant['2']\n",
    "    nano.add_dense_with_requant(q_weights['2']['weights'].flatten().tolist(), bc, m, s)\n",
    "    nano.add_relu()\n",
    "    m, s, bc = requant['4']\n",
    "    nano.add_dense_with_requant(q_weights['4']['weights'].flatten().tolist(), bc, m, s)\n",
    "    return nano\n",
    "\n",
    "# Test both\n",
    "correct_pt, correct_nano, match_count = 0, 0, 0\n",
    "max_diffs = []\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    x_f = torch.from_numpy(X_test[i:i+1]).to(device)\n",
    "    label = int(y_test[i])\n",
    "    q_x, _ = quantize_to_i8(X_test[i])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pt_out = model(x_f).numpy().flatten()\n",
    "    pt_cls = int(np.argmax(pt_out))\n",
    "    \n",
    "    nano_out = build_nano().forward(q_x.tolist())\n",
    "    nano_cls = int(np.argmax(nano_out))\n",
    "    \n",
    "    q_pt, _ = quantize_to_i8(pt_out)\n",
    "    diff = np.abs(q_pt.astype(np.int32) - np.array(nano_out, dtype=np.int8).astype(np.int32))\n",
    "    max_diffs.append(int(np.max(diff)))\n",
    "    \n",
    "    if pt_cls == label: correct_pt += 1\n",
    "    if nano_cls == label: correct_nano += 1\n",
    "    if nano_cls == pt_cls: match_count += 1\n",
    "\n",
    "N = len(X_test)\n",
    "print('=' * 60)\n",
    "print('       SENSOR FUSION MLP RESULTS')\n",
    "print('=' * 60)\n",
    "print(f'PyTorch Accuracy:     {100.*correct_pt/N:.1f}%')\n",
    "print(f'NANO-RUST Accuracy:   {100.*correct_nano/N:.1f}%')\n",
    "print(f'Classification Match: {100.*match_count/N:.1f}%')\n",
    "print(f'Max Diff (median):    {int(np.median(max_diffs))}')\n",
    "print(f'Max Diff (95th):      {int(np.percentile(max_diffs, 95))}')\n",
    "print('=' * 60)\n",
    "print(f'\\n\ud83d\udcca Memory: {sum(q[\"weights\"].nbytes for q in q_weights.values() if q[\"weights\"] is not None)} bytes (weights only)')\n",
    "print(f'This MLP fits on ANY microcontroller \u2014 even ATmega328 (2KB RAM)!')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NanoRust (venv)",
   "language": "python",
   "name": "nanorust"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}