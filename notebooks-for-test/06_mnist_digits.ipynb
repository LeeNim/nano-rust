{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 â€” MNIST Handwritten Digit Classification\n",
    "\n",
    "**Goal**: Train a CNN in PyTorch on MNIST, quantize to i8, run inference in NANO-RUST.\n",
    "\n",
    "Architecture: `Conv2D(1â†’8, 3Ã—3) â†’ ReLU â†’ MaxPool(2Ã—2) â†’ Conv2D(8â†’16, 3Ã—3) â†’ ReLU â†’ MaxPool(2Ã—2) â†’ Flatten â†’ Dense(400â†’10)`\n",
    "\n",
    "### Setup\n",
    "1. Ensure you're using the **NanoRust (venv)** kernel\n",
    "2. First cell builds the library via `maturin develop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸  WARNING: Not running inside a virtual environment!\n",
      "   Create one: python -m venv .venv\n",
      "   Activate:   .venv\\Scripts\\activate  (Windows)\n",
      "   Install:    pip install maturin numpy torch torchvision jupyter ipykernel\n",
      "   Register:   python -m ipykernel install --user --name nanorust\n",
      "ðŸ”¨ Building nano_rust_py (target: C:\\Users\\suoya\\.nanorust_target)...\n",
      "âŒ Build failed:\n",
      "Ã°Å¸â€™Â¥ maturin failed\n",
      "  Caused by: Failed to parse Cargo.toml at c:\\Users\\suoya\\OneDrive\\Documents\\nanorust\\Cargo.toml\n",
      "  Caused by: TOML parse error at line 1, column 1\n",
      "  |\n",
      "1 | [workspace]\n",
      "  | ^\n",
      "missing field `package`\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "maturin develop failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_setup.py\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43msetup_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\nanorust\\notebooks-for-test\\_setup.py:46\u001b[0m, in \u001b[0;36msetup_all\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâŒ Build failed:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 46\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaturin develop failed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… nano_rust_py built and installed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Verify import\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: maturin develop failed"
     ]
    }
   ],
   "source": [
    "%run _setup.py\n",
    "setup_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from nano_rust_utils import quantize_to_i8, quantize_weights, calibrate_model\n",
    "import nano_rust_py\n",
    "print('âœ… All modules loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "print(f'Train samples: {len(train_dataset)}')\n",
    "print(f'Test samples:  {len(test_dataset)}')\n",
    "print(f'Input shape:   {train_dataset[0][0].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define & Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=3, stride=1, padding=1),   # [1,28,28]â†’[8,28,28]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),                                     # â†’[8,14,14]\n",
    "            nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1),  # â†’[16,14,14]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),                                     # â†’[16,7,7]\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),                                           # â†’[784]\n",
    "            nn.Linear(16 * 7 * 7, 10),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = MNISTNet()\n",
    "print(model)\n",
    "print(f'Parameters: {sum(p.numel() for p in model.parameters()):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "EPOCHS = 3  # 3 epochs is enough for >97% accuracy\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        pred = output.argmax(dim=1)\n",
    "        correct += pred.eq(target).sum().item()\n",
    "        total += target.size(0)\n",
    "    \n",
    "    acc = 100. * correct / total\n",
    "    print(f'Epoch {epoch+1}/{EPOCHS} â€” Loss: {total_loss/len(train_loader):.4f}, Acc: {acc:.1f}%')\n",
    "\n",
    "model = model.cpu().eval()\n",
    "print('âœ… Training complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: PyTorch Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct_pt = 0\n",
    "total_pt = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1)\n",
    "        correct_pt += pred.eq(target).sum().item()\n",
    "        total_pt += target.size(0)\n",
    "pt_accuracy = 100. * correct_pt / total_pt\n",
    "print(f'PyTorch Test Accuracy: {pt_accuracy:.2f}% ({correct_pt}/{total_pt})')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Quantize & Build NANO-RUST Model\n",
    "\n",
    "We need to export the model as a flat `nn.Sequential` for `calibrate_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the model into nn.Sequential for calibration\n",
    "flat_\n",
    "# GPU Setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "if device.type == 'cuda':\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "\n",
    "model = nn.Sequential(\n",
    "    model.features[0],  # Conv2d(1,8,3,1,1)\n",
    "    model.features[1],  # ReLU\n",
    "    model.features[2],  # MaxPool2d(2,2)\n",
    "    model.features[3],  # Conv2d(8,16,3,1,1)\n",
    "    model.features[4],  # ReLU\n",
    "    model.features[5],  # MaxPool2d(2,2)\n",
    "    nn.Flatten(),        # Flatten\n",
    "    model.classifier[1], # Linear(784,10)\n",
    ")\n",
    "flat_model.eval()\n",
    "print('Flat model:', flat_model)\n",
    "\n",
    "q_weights = quantize_weights(flat_model)\n",
    "print(f\"\\nQuantized layers: {list(q_weights.keys())}\")\n",
    "for name, info in q_weights.items():\n",
    "    if info['weights'] is not None:\n",
    "        print(f\"  {name} ({info['type']}): weights={info['weights'].shape}, scale={info['weight_scale']:.6f}\")\n",
    "\n",
    "model = model.to(device)\n",
    "print(\"Model moved to device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibrate with a representative sample\n",
    "cal_image = test_dataset[0][0].unsqueeze(0)  # [1, 1, 28, 28]\n",
    "q_cal, cal_scale = quantize_to_i8(cal_image.numpy().flatten())\n",
    "\n",
    "requant = calibrate_model(flat_model, cal_image, q_weights, cal_scale)\n",
    "print('Calibration results:')\n",
    "for name, params in requant.items():\n",
    "    if isinstance(params[0], str):\n",
    "        print(f'  Layer {name}: {params[0]} scale_mult={params[1]}, scale_shift={params[2]}')\n",
    "    else:\n",
    "        print(f'  Layer {name}: M={params[0]}, shift={params[1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build NANO-RUST model\n",
    "def build_nano_model(q_weights, requant):\n",
    "    nano = nano_rust_py.PySequentialModel(input_shape=[1, 28, 28], arena_size=131072)\n",
    "    \n",
    "    # Conv2d(1â†’8, 3Ã—3, stride=1, pad=1)\n",
    "    m, s, bc = requant['0']\n",
    "    nano.add_conv2d_with_requant(\n",
    "        q_weights['0']['weights'].flatten().tolist(), bc,\n",
    "        1, 8, 3, 3, 1, 1, m, s)\n",
    "    nano.add_relu()\n",
    "    nano.add_max_pool2d(2, 2, 2)\n",
    "    \n",
    "    # Conv2d(8â†’16, 3Ã—3, stride=1, pad=1)\n",
    "    m, s, bc = requant['3']\n",
    "    nano.add_conv2d_with_requant(\n",
    "        q_weights['3']['weights'].flatten().tolist(), bc,\n",
    "        8, 16, 3, 3, 1, 1, m, s)\n",
    "    nano.add_relu()\n",
    "    nano.add_max_pool2d(2, 2, 2)\n",
    "    \n",
    "    # Flatten + Dense(784â†’10)\n",
    "    nano.add_flatten()\n",
    "    m, s, bc = requant['7']\n",
    "    nano.add_dense_with_requant(\n",
    "        q_weights['7']['weights'].flatten().tolist(), bc, m, s)\n",
    "    \n",
    "    return nano\n",
    "\n",
    "nano = build_nano_model(q_weights, requant)\n",
    "print('âœ… NANO-RUST model built')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: NANO-RUST Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on the full test set\n",
    "correct_nano = 0\n",
    "correct_match = 0  # Agreement between PyTorch and NANO-RUST\n",
    "total_test = 0\n",
    "max_diffs = []\n",
    "\n",
    "N_TEST = min(1000, len(test_dataset))  # Test on first 1000 samples\n",
    "\n",
    "for i in range(N_TEST):\n",
    "    image, label = test_dataset[i]\n",
    "    image_np = image.numpy().flatten()\n",
    "    q_image, _ = quantize_to_i8(image_np)\n",
    "    \n",
    "    # NANO-RUST inference\n",
    "    nano_model = build_nano_model(q_weights, requant)\n",
    "    nano_out = nano_model.forward(q_image.tolist())\n",
    "    nano_class = int(np.argmax(nano_out))\n",
    "    \n",
    "    # PyTorch reference\n",
    "    with torch.no_grad():\n",
    "        pt_out = flat_model(image.unsqueeze(0)).numpy().flatten()\n",
    "    pt_class = int(np.argmax(pt_out))\n",
    "    \n",
    "    # Compare\n",
    "    q_pt, _ = quantize_to_i8(pt_out)\n",
    "    nano_arr = np.array(nano_out, dtype=np.int8)\n",
    "    diff = np.abs(q_pt.astype(np.int32) - nano_arr.astype(np.int32))\n",
    "    max_diffs.append(int(np.max(diff)))\n",
    "    \n",
    "    if nano_class == label:\n",
    "        correct_nano += 1\n",
    "    if nano_class == pt_class:\n",
    "        correct_match += 1\n",
    "    total_test += 1\n",
    "\n",
    "nano_accuracy = 100. * correct_nano / total_test\n",
    "agreement = 100. * correct_match / total_test\n",
    "\n",
    "print('=' * 60)\n",
    "print('       MNIST CLASSIFICATION RESULTS')\n",
    "print('=' * 60)\n",
    "print(f'PyTorch Accuracy:      {pt_accuracy:.2f}%')\n",
    "print(f'NANO-RUST Accuracy:    {nano_accuracy:.2f}% (on {N_TEST} samples)')\n",
    "print(f'Classification Match:  {agreement:.1f}%')\n",
    "print(f'Max i8 Diff (median):  {int(np.median(max_diffs))}')\n",
    "print(f'Max i8 Diff (95th):    {int(np.percentile(max_diffs, 95))}')\n",
    "print(f'Max i8 Diff (max):     {max(max_diffs)}')\n",
    "print('=' * 60)\n",
    "print(f'{\"âœ… PASS\" if agreement > 90 else \"âŒ FAIL\"}: {agreement:.1f}% classification agreement')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Memory Budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nðŸ“Š Memory Budget for MCU Deployment')\n",
    "print('=' * 50)\n",
    "total_flash = 0\n",
    "for name, info in q_weights.items():\n",
    "    if info['weights'] is not None:\n",
    "        w_bytes = info['weights'].nbytes\n",
    "        b_bytes = len(requant[name][2]) if name in requant and not isinstance(requant[name][0], str) else 0\n",
    "        total_flash += w_bytes + b_bytes\n",
    "        print(f'  Layer {name} ({info[\"type\"]}): {w_bytes + b_bytes:>6} bytes')\n",
    "\n",
    "# Arena = largest intermediate buffer\n",
    "# After Conv1: 8*28*28 = 6272 bytes\n",
    "# After Pool1: 8*14*14 = 1568 bytes\n",
    "# After Conv2: 16*14*14 = 3136 bytes\n",
    "# After Pool2: 16*7*7 = 784 bytes\n",
    "# im2col buffer: max(1*3*3*28*28, 8*3*3*14*14) = max(7056, 14112) = 14112\n",
    "arena_est = 32768  # Conservative estimate\n",
    "\n",
    "print(f'\\n  Total Flash: {total_flash:>6} bytes ({total_flash/1024:.1f} KB)')\n",
    "print(f'  Arena (RAM): {arena_est:>6} bytes ({arena_est/1024:.1f} KB)')\n",
    "print(f'  Total:       {total_flash+arena_est:>6} bytes ({(total_flash+arena_est)/1024:.1f} KB)')\n",
    "print(f'\\n  Fits ESP32 (520KB RAM)?     {\"âœ…\" if arena_est < 520*1024 else \"âŒ\"}')\n",
    "print(f'  Fits STM32F4 (192KB RAM)?   {\"âœ…\" if arena_est < 192*1024 else \"âŒ\"}')\n",
    "print(f'  Fits STM32L4 (96KB RAM)?    {\"âœ…\" if arena_est < 96*1024 else \"âŒ\"}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
